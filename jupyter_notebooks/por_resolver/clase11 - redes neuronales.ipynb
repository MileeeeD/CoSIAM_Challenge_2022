{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='../img/logo_cosiam/LogoCoSIAM_COL.png' style='height:230px;  margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "# M√≥dulo 10: Redes neuronales\n",
    "\n",
    "- Introducci√≥n a las redes neuronales\n",
    "- Transformers con Hugging Face\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# En cap√≠tulos anteriores...\n",
    "\n",
    "<br>\n",
    "<center><img src='../img/pipeline/pipeline5b.png' style='height:600px;'> </centeR>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# En cap√≠tulos anteriores...\n",
    "\n",
    "<br>\n",
    "<center><img src='../img/pipeline/pipeline5b.png' style='height:600px;'> </centeR>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hoy: Regresemos a modelar\n",
    "\n",
    "<br>\n",
    "<center><img src='../img/pipeline/pipeline6.png' style='height:600px;'> </centeR>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ¬øQu√© es NLP?\n",
    "\n",
    "<center><img src='../img/clase11/vector.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "<br>\n",
    "\n",
    "- El **Procesamiento de Lenguaje Natural** es una √°rea de la Inteligencia Artificial que permite a los computadores entender, interpretar y usar el lenguaje humano. Es una herramienta que nos permite obtener informaci√≥n a partir del lenguaje humano (normalmente textos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evoluci√≥n de NLP\n",
    "\n",
    "<center><img src='../img/clase11/evol.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "<br>\n",
    "\n",
    "- 1950: Alan Turing describi√≥ una \"m√°quina pensante\". Afirm√≥ que si una m√°quina pudiera participar en una conversaci√≥n e imitara a un humano de forma tan completa que no hubiera diferencias perceptibles, entonces la m√°quina podr√≠a considerarse capaz de pensar. <br><br>\n",
    "\n",
    "- 1952: El modelo Hodgkin-Huxley mostr√≥ c√≥mo el cerebro utiliza las neuronas para formar una red el√©ctrica. <br><br>\n",
    "\n",
    "- ^ Eso inspir√≥ la creaci√≥n de AI & NLP & la evoluci√≥n de los computadores. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evoluci√≥n de NLP\n",
    "\n",
    "<center><img src='../img/clase11/evol.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "<br>\n",
    "\n",
    "- 1954: **Bag of Words**\n",
    "\n",
    "    - Cuenta la ocurrencia de palabras en un documento.\n",
    "    - D√≠ficil de aplicar en la vida real porque r√°pidamente ocupa mucha memoria y es dominado por las palabras vac√≠as."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evoluci√≥n de NLP\n",
    "\n",
    "<center><img src='../img/clase11/evol.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "<br>\n",
    "\n",
    "- 1972: **TF-IDF**\n",
    "\n",
    "    - Elimin√≥ el problema de las palabras vac√≠as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evoluci√≥n de NLP\n",
    "\n",
    "<center><img src='../img/clase11/evol.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "<br>\n",
    "\n",
    "- 2013: **Word2Vec**\n",
    "\n",
    "    - T√©cnica que toma encuenta la relaci√≥n sem√°ntica entre palabras\n",
    "    - De los primeros modelos que usaron t√©cnicas de predicci√≥n y redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evoluci√≥n de NLP\n",
    "\n",
    "<center><img src='../img/clase11/evol.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "<br>\n",
    "\n",
    "- 2018: **Transformers**\n",
    "\n",
    "    - Modelos que usan atenci√≥n para aumentar la velocidad del entrenamiento en tareas espec√≠ficas. \n",
    "    \n",
    "**Recordemos** que NLP tiene muchas aplicaciones en la vida real que usan diferentes t√©cnicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evoluci√≥n de NLP\n",
    "\n",
    "<br>\n",
    "<center><img src='../img/clase11/evolnnn.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "<br>\n",
    "\n",
    "- Encoder: ALBERT, BERT, DistilBERT, ELECTRA, RoBERTa\n",
    "- Decoder: CTRL, GPT, GPT-2, Transformer XL\n",
    "- Seq2Seq: BART, mBART, Marian, T5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üß† Redes Neuronales\n",
    "\n",
    "YouTube: https://www.youtube.com/watch?v=cQ54GDm1eL0&ab_channel=BuzzFeedVideo\n",
    "\n",
    "- Una red neuronal est√° compuesta de neuronas\n",
    "- Las **Redes Neuronales Artifciales** (ANN) est√°n inspiradas las redes neuronales biol√≥gicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üß† Una neurona biol√≥gica\n",
    "\n",
    "<center><img src='../img/clase11/neu.png' style='height:300px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "De una manera simplificada:\n",
    "- Las dendritas alimentan el cuerpo de la c√©lula a trav√©s de se√±ales el√©ctricas\n",
    "- La respuesta es despu√©s pasada a trav√©s del ax√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üß† Una neurona artificial = Perceptr√≥n \n",
    "\n",
    "<center><img src='../img/clase11/perceptron.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üß† Una neurona artificial = Perceptr√≥n \n",
    "\n",
    "<center><img src='../img/clase11/p1.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- Como todo modelo de *machine learning*, tenemos valores de entrada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üß† Una neurona artificial = Perceptr√≥n \n",
    "\n",
    "<center><img src='../img/clase11/p2b.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- Despu√©s, los valores de entrada son multiplicados por pesos\n",
    "- Estos pesos son inicializados de manera aleatoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üß† Una neurona artificial = Perceptr√≥n \n",
    "\n",
    "<center><img src='../img/clase11/p3.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- El resultado (en este ejemplo $12\\cdot.5 + 4\\cdot-1 = 2$) se pasa por una funci√≥n de activaci√≥n\n",
    "- Existen muchas funciones de activaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üß† Una neurona artificial = Perceptr√≥n \n",
    "\n",
    "<center><img src='../img/clase11/p4.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- El resultado (en este ejemplo $12\\cdot.5 + 4\\cdot-1 = 2$) se pasa por una funci√≥n de activaci√≥n\n",
    "- Existen muchas funciones de activaci√≥n: **EJEMPLO**: Positiva=1, Negativa=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üß† Una neurona artificial = Perceptr√≥n \n",
    "<br>\n",
    "<center><img src='../img/clase11/p5.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- Se agrega un sesgo para evitar problemas matem√°ticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üß† Una red neuronal artificial\n",
    "<br>\n",
    "<center><img src='../img/clase11/p5.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- Matem√°ticamente tenemos:\n",
    "$$\\sum^{n}_{i=0}w_ix_i + b$$\n",
    "<br>\n",
    "- Cuando tenemos una red neuronal compuesta de varios perceptrones, se extiende a forma matricial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üß† Una red neuronal artificial\n",
    "<br>\n",
    "<center><img src='../img/clase11/ann.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "Partes:\n",
    "- Capa de entrada (input): Valores reales de los datos\n",
    "- Capas ocultas (2 en este caso): Deep network\n",
    "- Capa de salida (output): Estimado final\n",
    "\n",
    "A medida que crece el n√∫mero de capas, crece el nivel de abstracci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üëÆ‚Äç‚ôÄÔ∏è Punto de control\n",
    "<br>\n",
    "<center><img src='../img/clase11/control.png' style='height:300px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "### ¬øCu√°ntas capas ocultas tiene esta red neuronal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üí• Funci√≥n de activaci√≥n\n",
    "<br>\n",
    "<center><img src='../img/clase11/fa1.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- Asigna 0 si el valor es menor a 0, asigna 1 si el valor es mayor o igual a cero\n",
    "- Muy dr√°stica, peque√±os cambios no son reflejados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üí• Funci√≥n de activaci√≥n\n",
    "<br>\n",
    "<center><img src='../img/clase11/fa2.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- **Funci√≥n sigmoide:** $f(x)=\\dfrac{1}{1+e^{-(x)}}$\n",
    "- Muy √∫til dependiendo de la tarea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üí• Funci√≥n de activaci√≥n\n",
    "<br>\n",
    "<center><img src='../img/clase11/fa3.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- **Funci√≥n de la tangente hiperb√≥lica:** $\\tanh x=\\dfrac{\\sinh x}{\\cosh x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üí• Funci√≥n de activaci√≥n\n",
    "<br>\n",
    "<center><img src='../img/clase11/fa4.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- **Funci√≥n ReLU** (Rectificador lineal): $max(0,x)$\n",
    "- Aunque es sencilla, tiene muy buen desempe√±o en muchas situaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üß† RNN: Redes Neuronales Recurrentes\n",
    "\n",
    "- Dise√±adas para trabajar con datos de **secuencia **\n",
    "    - Series de tiempo\n",
    "    - Frases\n",
    "    - Audio\n",
    "    - Trayector√≠a de carros\n",
    "    - M√∫sica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üß† RNN: Redes Neuronales Recurrentes\n",
    "<br>\n",
    "<center><img src='../img/clase11/rnnvsann.png' style='height:450px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- Se env√≠a el resultado a s√≠ misma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ü§î RNN: Redes Neuronales Recurrentes\n",
    "\n",
    "- Un problema de las RNN es que empiezan a olvidar los primeros datos de entrada\n",
    "- Soluciones: \n",
    "    - LSTM (Long Short-Term Memory) \n",
    "    - GRU (Gated Recurrent Unit)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Notebook de Redes Neuronales\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ü§ó Transformers con Hugging FAce\n",
    "<br>\n",
    "<center><img src='../img/clase11/trans.jpeg' style='height:300px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- [Hugging Face](https://huggingface.co/) es una startup que ofrece 30 modulos pre-entrenados en m√°s de 100 idiomas y 8 arquitecturas para NLU & NLG.\n",
    "\n",
    "    - BERT (from Google);\n",
    "    - GPT (from OpenAI);\n",
    "    - GPT-2 (from OpenAI);\n",
    "    - Transformer-XL (from Google/CMU);\n",
    "    - XLNet (from Google/CMU);\n",
    "    - XLM (from Facebook);\n",
    "    - RoBERTa (from Facebook);\n",
    "    - DistilBERT (from Hugging Face).\n",
    "    \n",
    "    \n",
    "- Recurso: https://www.kdnuggets.com/2021/02/hugging-face-transformer-basics.html\n",
    "- Recurso: https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ¬øQu√© pueden hacer los transformers?\n",
    "\n",
    "- `pip install transformers`\n",
    "- Si se presentan problemas: `pip install datasets evaluate transformers[sentencepiece]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### An√°lisis de sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### An√°lisis de sentimiento en espa√±ol\n",
    "https://huggingface.co/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clasificaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generaci√≥n de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Llenar los blancos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### NER: Named Entity Recognition (Reconocimiento de entidades nombradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Responder preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Traducci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Enlaces de referencia \n",
    "\n",
    "- https://huggingface.co/models\n",
    "- https://huggingface.co/docs/transformers/main/en/main_classes/pipelines\n",
    "- https://huggingface.co/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ü§ì Recapitulando: Hoy aprend√≠mos...\n",
    "\n",
    "- Evoluci√≥n de NLP\n",
    "- Panorama general sobre las redes neuronales\n",
    "- RNN (Red neuronal recurrente) para generar texto\n",
    "- Transformers con HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='../img/dragonball/11.jpeg' style='height:600px; float: left; margin: 0px 15px 15px 0px'>\n",
    "\n",
    "‚Ä¢ **M√≥dulo 1**: &nbsp;&nbsp;&nbsp;&nbsp; Introducci√≥n ‚úÖ <br>\n",
    "‚Ä¢ **M√≥dulo 2**: &nbsp;&nbsp;&nbsp;&nbsp; Configuraci√≥n de ambiente de desarrollo ‚úÖ <br>\n",
    "‚Ä¢ **M√≥dulo 3**: &nbsp;&nbsp;&nbsp;&nbsp; Repaso de Python ‚úÖ <br>\n",
    "‚Ä¢ **M√≥dulo 4**: &nbsp;&nbsp;&nbsp;&nbsp; Panorama general del Aprendizaje Autom√°tico (Machine Learning) ‚úÖ <br>\n",
    "‚Ä¢ **M√≥dulo 5**: &nbsp;&nbsp;&nbsp;&nbsp; ¬øC√≥mo adquirir datos? ‚úÖ <br>\n",
    "‚Ä¢ **M√≥dulo 6**: &nbsp;&nbsp;&nbsp;&nbsp; Cuenta de desarrollador de Twitter ‚úÖ <br>\n",
    "‚Ä¢ **M√≥dulo 7**: &nbsp;&nbsp;&nbsp;&nbsp; Web Scraping ‚úÖ <br>\n",
    "‚Ä¢ **M√≥dulo 8**: &nbsp;&nbsp;&nbsp;&nbsp; De palabras a vectores ‚úÖ <br>\n",
    "‚Ä¢ **M√≥dulo 9**: &nbsp;&nbsp;&nbsp;&nbsp; Modelos de Machine Learning ‚úÖ <br>\n",
    "‚Ä¢ **M√≥dulo 10**: &nbsp; Visualizaciones ‚úÖ<br>\n",
    "‚Ä¢ **M√≥dulo 11**: &nbsp; Introducci√≥n a redes neuronales & Hugging Face ‚úÖ<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ¬°Eso es todo sobre la introducci√≥n a la ciencia de datos a trav√©s del procesamiento de lenguaje natural!\n",
    "<br>\n",
    "<img src='../img/dragonball/all.jpeg' style='height:400px;'>\n",
    "\n",
    "¬°√âxitos en el challenge!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
