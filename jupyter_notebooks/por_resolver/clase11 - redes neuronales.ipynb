{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='../img/logo_cosiam/LogoCoSIAM_COL.png' style='height:230px;  margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "# Módulo 10: Redes neuronales\n",
    "\n",
    "- Introducción a las redes neuronales\n",
    "- Transformers con Hugging Face\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# En capítulos anteriores...\n",
    "\n",
    "<br>\n",
    "<center><img src='../img/pipeline/pipeline5b.png' style='height:600px;'> </centeR>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# En capítulos anteriores...\n",
    "\n",
    "<br>\n",
    "<center><img src='../img/pipeline/pipeline5b.png' style='height:600px;'> </centeR>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hoy: Regresemos a modelar\n",
    "\n",
    "<br>\n",
    "<center><img src='../img/pipeline/pipeline6.png' style='height:600px;'> </centeR>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ¿Qué es NLP?\n",
    "\n",
    "<center><img src='../img/clase11/vector.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "<br>\n",
    "\n",
    "- El **Procesamiento de Lenguaje Natural** es una área de la Inteligencia Artificial que permite a los computadores entender, interpretar y usar el lenguaje humano. Es una herramienta que nos permite obtener información a partir del lenguaje humano (normalmente textos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evolución de NLP\n",
    "\n",
    "<center><img src='../img/clase11/evol.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "<br>\n",
    "\n",
    "- 1950: Alan Turing describió una \"máquina pensante\". Afirmó que si una máquina pudiera participar en una conversación e imitara a un humano de forma tan completa que no hubiera diferencias perceptibles, entonces la máquina podría considerarse capaz de pensar. <br><br>\n",
    "\n",
    "- 1952: El modelo Hodgkin-Huxley mostró cómo el cerebro utiliza las neuronas para formar una red eléctrica. <br><br>\n",
    "\n",
    "- ^ Eso inspiró la creación de AI & NLP & la evolución de los computadores. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evolución de NLP\n",
    "\n",
    "<center><img src='../img/clase11/evol.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "<br>\n",
    "\n",
    "- 1954: **Bag of Words**\n",
    "\n",
    "    - Cuenta la ocurrencia de palabras en un documento.\n",
    "    - Díficil de aplicar en la vida real porque rápidamente ocupa mucha memoria y es dominado por las palabras vacías."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evolución de NLP\n",
    "\n",
    "<center><img src='../img/clase11/evol.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "<br>\n",
    "\n",
    "- 1972: **TF-IDF**\n",
    "\n",
    "    - Eliminó el problema de las palabras vacías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evolución de NLP\n",
    "\n",
    "<center><img src='../img/clase11/evol.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "<br>\n",
    "\n",
    "- 2013: **Word2Vec**\n",
    "\n",
    "    - Técnica que toma encuenta la relación semántica entre palabras\n",
    "    - De los primeros modelos que usaron técnicas de predicción y redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evolución de NLP\n",
    "\n",
    "<center><img src='../img/clase11/evol.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "<br>\n",
    "\n",
    "- 2018: **Transformers**\n",
    "\n",
    "    - Modelos que usan atención para aumentar la velocidad del entrenamiento en tareas específicas. \n",
    "    \n",
    "**Recordemos** que NLP tiene muchas aplicaciones en la vida real que usan diferentes técnicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evolución de NLP\n",
    "\n",
    "<br>\n",
    "<center><img src='../img/clase11/evolnnn.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "<br>\n",
    "\n",
    "- Encoder: ALBERT, BERT, DistilBERT, ELECTRA, RoBERTa\n",
    "- Decoder: CTRL, GPT, GPT-2, Transformer XL\n",
    "- Seq2Seq: BART, mBART, Marian, T5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 🧠 Redes Neuronales\n",
    "\n",
    "YouTube: https://www.youtube.com/watch?v=cQ54GDm1eL0&ab_channel=BuzzFeedVideo\n",
    "\n",
    "- Una red neuronal está compuesta de neuronas\n",
    "- Las **Redes Neuronales Artifciales** (ANN) están inspiradas las redes neuronales biológicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 🧠 Una neurona biológica\n",
    "\n",
    "<center><img src='../img/clase11/neu.png' style='height:300px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "De una manera simplificada:\n",
    "- Las dendritas alimentan el cuerpo de la célula a través de señales eléctricas\n",
    "- La respuesta es después pasada a través del axón"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 🧠 Una neurona artificial = Perceptrón \n",
    "\n",
    "<center><img src='../img/clase11/perceptron.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 🧠 Una neurona artificial = Perceptrón \n",
    "\n",
    "<center><img src='../img/clase11/p1.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- Como todo modelo de *machine learning*, tenemos valores de entrada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 🧠 Una neurona artificial = Perceptrón \n",
    "\n",
    "<center><img src='../img/clase11/p2b.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- Después, los valores de entrada son multiplicados por pesos\n",
    "- Estos pesos son inicializados de manera aleatoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 🧠 Una neurona artificial = Perceptrón \n",
    "\n",
    "<center><img src='../img/clase11/p3.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- El resultado (en este ejemplo $12\\cdot.5 + 4\\cdot-1 = 2$) se pasa por una función de activación\n",
    "- Existen muchas funciones de activación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 🧠 Una neurona artificial = Perceptrón \n",
    "\n",
    "<center><img src='../img/clase11/p4.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- El resultado (en este ejemplo $12\\cdot.5 + 4\\cdot-1 = 2$) se pasa por una función de activación\n",
    "- Existen muchas funciones de activación: **EJEMPLO**: Positiva=1, Negativa=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 🧠 Una neurona artificial = Perceptrón \n",
    "<br>\n",
    "<center><img src='../img/clase11/p5.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- Se agrega un sesgo para evitar problemas matemáticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 🧠 Una red neuronal artificial\n",
    "<br>\n",
    "<center><img src='../img/clase11/p5.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- Matemáticamente tenemos:\n",
    "$$\\sum^{n}_{i=0}w_ix_i + b$$\n",
    "<br>\n",
    "- Cuando tenemos una red neuronal compuesta de varios perceptrones, se extiende a forma matricial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 🧠 Una red neuronal artificial\n",
    "<br>\n",
    "<center><img src='../img/clase11/ann.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "Partes:\n",
    "- Capa de entrada (input): Valores reales de los datos\n",
    "- Capas ocultas (2 en este caso): Deep network\n",
    "- Capa de salida (output): Estimado final\n",
    "\n",
    "A medida que crece el número de capas, crece el nivel de abstracción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 👮‍♀️ Punto de control\n",
    "<br>\n",
    "<center><img src='../img/clase11/control.png' style='height:300px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "### ¿Cuántas capas ocultas tiene esta red neuronal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 💥 Función de activación\n",
    "<br>\n",
    "<center><img src='../img/clase11/fa1.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- Asigna 0 si el valor es menor a 0, asigna 1 si el valor es mayor o igual a cero\n",
    "- Muy drástica, pequeños cambios no son reflejados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 💥 Función de activación\n",
    "<br>\n",
    "<center><img src='../img/clase11/fa2.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- **Función sigmoide:** $f(x)=\\dfrac{1}{1+e^{-(x)}}$\n",
    "- Muy útil dependiendo de la tarea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 💥 Función de activación\n",
    "<br>\n",
    "<center><img src='../img/clase11/fa3.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- **Función de la tangente hiperbólica:** $\\tanh x=\\dfrac{\\sinh x}{\\cosh x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 💥 Función de activación\n",
    "<br>\n",
    "<center><img src='../img/clase11/fa4.png' style='height:250px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- **Función ReLU** (Rectificador lineal): $max(0,x)$\n",
    "- Aunque es sencilla, tiene muy buen desempeño en muchas situaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 🧠 RNN: Redes Neuronales Recurrentes\n",
    "\n",
    "- Diseñadas para trabajar con datos de **secuencia **\n",
    "    - Series de tiempo\n",
    "    - Frases\n",
    "    - Audio\n",
    "    - Trayectoría de carros\n",
    "    - Música"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 🧠 RNN: Redes Neuronales Recurrentes\n",
    "<br>\n",
    "<center><img src='../img/clase11/rnnvsann.png' style='height:450px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- Se envía el resultado a sí misma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 🤔 RNN: Redes Neuronales Recurrentes\n",
    "\n",
    "- Un problema de las RNN es que empiezan a olvidar los primeros datos de entrada\n",
    "- Soluciones: \n",
    "    - LSTM (Long Short-Term Memory) \n",
    "    - GRU (Gated Recurrent Unit)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Notebook de Redes Neuronales\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 🤗 Transformers con Hugging FAce\n",
    "<br>\n",
    "<center><img src='../img/clase11/trans.jpeg' style='height:300px; float: center; margin: 0px 15px 15px 0px'></center>\n",
    "\n",
    "- [Hugging Face](https://huggingface.co/) es una startup que ofrece 30 modulos pre-entrenados en más de 100 idiomas y 8 arquitecturas para NLU & NLG.\n",
    "\n",
    "    - BERT (from Google);\n",
    "    - GPT (from OpenAI);\n",
    "    - GPT-2 (from OpenAI);\n",
    "    - Transformer-XL (from Google/CMU);\n",
    "    - XLNet (from Google/CMU);\n",
    "    - XLM (from Facebook);\n",
    "    - RoBERTa (from Facebook);\n",
    "    - DistilBERT (from Hugging Face).\n",
    "    \n",
    "    \n",
    "- Recurso: https://www.kdnuggets.com/2021/02/hugging-face-transformer-basics.html\n",
    "- Recurso: https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ¿Qué pueden hacer los transformers?\n",
    "\n",
    "- `pip install transformers`\n",
    "- Si se presentan problemas: `pip install datasets evaluate transformers[sentencepiece]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Análisis de sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Análisis de sentimiento en español\n",
    "https://huggingface.co/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generación de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Llenar los blancos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### NER: Named Entity Recognition (Reconocimiento de entidades nombradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Responder preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Traducción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Enlaces de referencia \n",
    "\n",
    "- https://huggingface.co/models\n",
    "- https://huggingface.co/docs/transformers/main/en/main_classes/pipelines\n",
    "- https://huggingface.co/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 🤓 Recapitulando: Hoy aprendímos...\n",
    "\n",
    "- Evolución de NLP\n",
    "- Panorama general sobre las redes neuronales\n",
    "- RNN (Red neuronal recurrente) para generar texto\n",
    "- Transformers con HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='../img/dragonball/11.jpeg' style='height:600px; float: left; margin: 0px 15px 15px 0px'>\n",
    "\n",
    "• **Módulo 1**: &nbsp;&nbsp;&nbsp;&nbsp; Introducción ✅ <br>\n",
    "• **Módulo 2**: &nbsp;&nbsp;&nbsp;&nbsp; Configuración de ambiente de desarrollo ✅ <br>\n",
    "• **Módulo 3**: &nbsp;&nbsp;&nbsp;&nbsp; Repaso de Python ✅ <br>\n",
    "• **Módulo 4**: &nbsp;&nbsp;&nbsp;&nbsp; Panorama general del Aprendizaje Automático (Machine Learning) ✅ <br>\n",
    "• **Módulo 5**: &nbsp;&nbsp;&nbsp;&nbsp; ¿Cómo adquirir datos? ✅ <br>\n",
    "• **Módulo 6**: &nbsp;&nbsp;&nbsp;&nbsp; Cuenta de desarrollador de Twitter ✅ <br>\n",
    "• **Módulo 7**: &nbsp;&nbsp;&nbsp;&nbsp; Web Scraping ✅ <br>\n",
    "• **Módulo 8**: &nbsp;&nbsp;&nbsp;&nbsp; De palabras a vectores ✅ <br>\n",
    "• **Módulo 9**: &nbsp;&nbsp;&nbsp;&nbsp; Modelos de Machine Learning ✅ <br>\n",
    "• **Módulo 10**: &nbsp; Visualizaciones ✅<br>\n",
    "• **Módulo 11**: &nbsp; Introducción a redes neuronales & Hugging Face ✅<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ¡Eso es todo sobre la introducción a la ciencia de datos a través del procesamiento de lenguaje natural!\n",
    "<br>\n",
    "<img src='../img/dragonball/all.jpeg' style='height:400px;'>\n",
    "\n",
    "¡Éxitos en el challenge!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
